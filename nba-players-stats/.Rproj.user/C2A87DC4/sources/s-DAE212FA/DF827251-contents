#homework2
#abhishek Rai
#BUAN-6356



# (a) Import the data to R. Copy the R code used below. 

organic.df<-read.csv("organics.csv")
# 
# (b) Examine the distribution of the target variable: 
#(1) plot a bar chart to show the number of observations in each category,

summary(organic.df)
xx<-barplot(height=table(organic.df$TargetBuy),xlab = "Target Bought product ",names.arg=
          c('No','Yes'),ylab="No of observations",col='DArk Green')

#xx<-barplot(height=table(organic.df$TargetBuy), col="#69b3a2")
text(x = xx, y = table(organic.df$TargetBuy), label = table(organic.df$TargetBuy),pos = 1)


#and (2) plot a bar chart to show the frequency of observations in each 
# category. Copy the code used and the resulting plots below.

library(plyr)
TargetFreq<-count(organic.df$TargetBuy)
TargetFreq
barplot(height = TargetFreq$freq,name=TargetFreq$x,ylab="frequency")


#How many individuals purchased organic products?
#What is the approximate proportion of individuals who purchased organic product
# Simple Bar Plot
 
#   (c) The variable DemClusterGroup contains collapsed levels of the variable 
#DemCluster. Presume that, based on previous experience, you believe that 
#DemClusterGroup is sufficient for this type of modeling effort. 
#Exclude the variable DemCluster for the analysis. Copy the R code used below. 
#
organic.df<-organic.df[,-c(4)]


# (d) As noted above, only TargetBuy will be used for this analysis and should have
#a role of target.Can TargetAmt be used as an input for a model used to 
#predict TargetBuy? Why or why not? 

#No
organic.df<-organic.df[,-c(12)]

# (e) Partition the data: set records 1, 3, 5, . (the rows with odd numbers) as the 
# training data, and set records 2, 4, 6, . (the rows with even numbers) as the validation
# data, which results in 50%/50% partition for training/validation.
# Copy the code used below. 
training.Index<-sample(c(TRUE,FALSE),)
training.Index.vd<-sample(c(TRUE,FALSE),)
t.df<-organic.df[training.Index,]
v.df<-organic.df[training.Index.vd,]


# 
# (f) Implement a decision tree on the Training data to predict "TargetBuy" status.
#Plot the tree. Copy the code used and the result below. How many leaves are in the tree?
#   Which variable was used for the first split?
#   Create a confusion matrix which shows the accuracy rate of your classification.
# Copy the code used and the result below. 

library(rpart)
library(rpart.plot)
basic.dt<-rpart(TargetBuy~.,data = t.df,method = 'class')
prp(basic.dt)

#no of leaves:8
#Dem Age was used for the first split
install.packages("caret")
library(caret)

install.packages("lattice")
basicPredict.dt<-predict(basic.dt,t.df,type = 'class')
class(organic.df$TargetBuy)
confusionMatrix(basicPredict.dt,as.factor(t.df$TargetBuy))

# (g) Apply your decision tree from the training data to the validation data, and 
# compare the accuracy of classification of your validation and training data sets.
# Show the confusion matrix. Copy the code used and the results below. How is the 
# accuracy using validation data different from that using training data? 
#   Is this what you expected? Why? 

ValidPRedict.dt<-predict(basic.dt,v.df,type = 'class')
confusionMatrix(ValidPRedict.dt,as.factor(v.df$TargetBuy))
#

#(h) Imposing maxdepth = 2, create another decision tree on the training data 
# to predict TargetBuy status. Plot the tree. Create a confusion matrix which shows
# the accuracy rate of your classification.  Copy the code used and the result below.
# How many leaves are in the tree? Compared with the tree in (f), which one appears
# to be better? Is this what you expected? Why? 

custom.dt<-rpart(TargetBuy~.,data = t.df,method = "class",maxdepth= 2)
prp(custom.dt)

custom.predict.train.dt<-predict(custom.dt,t.df,type = 'class')
confusionMatrix(custom.predict.train.dt,as.factor(t.df$TargetBuy))

#(i) Next, consider using a logistic regression model. First, are there any missing
# values? If so, is any missing values imputation needed for logit model?
#   Is imputation required before generating the decision tree models and why? 

summary(organic.df)
# first of all we look at data in the summary and find that its not worth it to have ID in
# data set because it is not impacting the behaviour of the model and will not be benifical
# for any decsion making
organic.df<-organic.df[,-c(1)]
summary(organic.df)


#   Replacing blank values with NAs 

#   (j) Impute: impute "U" for unknown class variable values and the overall mean
# for unknown interval variable values. Copy the code used below. 

#replacing blank values with NA in every column.
try<-organic.df
summary(try)
try.df<-organic.df
library(dplyr)

try[try==""]<-NA
summary(try)

#NOW replacing NAs with U and mean values
mean(try$DemAffl,na.rm = TRUE)
try$DemAffl[is.na(try$DemAffl)]<-mean(try$DemAffl,na.rm=TRUE)
summary(try$DemAffl)
try$DemAge[is.na(try$DemAge)]<-mean(try$DemAge,na.rm=TRUE)
summary(try$DemAge)
#
try$PromTime[is.na(try$PromTime)]<-mean(try$PromTime,na.rm=TRUE)
summary(try$PromTime)

try$DemClusterGroup[is.na(try$DemClusterGroup)]<-'U'
summary(try$DemClusterGroup)

try$DemGender[is.na(try$DemGender)]<-'U'
summary(try$DemGender)


try$DemReg<-as.character(try$DemReg)
try$DemReg[is.na(try$DemReg)]<-'U'
summary(try$DemReg)
try$DemReg<-as.factor(try$DemReg)
summary(try$DemReg)


try$DemTVReg<-as.character(try$DemTVReg)
try$DemTVReg[is.na(try$DemTVReg)]<-'U'
summary(try$DemTVReg)
try$DemTVReg<-as.factor(try$DemTVReg)
summary(try$DemTVReg)

summary(try)

# (k) Use a logistic regression model to classify the data set using the same 
#dependent variable, TargetBuy. Copy the code used and the result below. 
# 

t.index.train<-sample(c(TRUE,FALSE),)
t.index.valid<-sample(c(FALSE,TRUE),)
t.l.df<-try[t.index.train,]
v.l.df<-try[t.index.valid,]

logit.reg<-glm(TargetBuy~.,data = t.l.df,family = "binomial")

summary(logit.reg)
# logit.reg[complete.cases(logit.reg$coefficients)]
# #to remove singularities in above data set
# 

# (l) Compare the performance of the logit model on the training and validation 
#data sets by creating confusion matrixes which show the accuracy rates. 
#Copy the code used and the result below. Which one appears to be better? 

options(warn = -1)
#to remove the warning message occured due to singularity in columns.
logitRegression.Prediction.train<-predict(logit.reg,t.l.df,type = "response")
confusionMatrix(as.factor(ifelse(logitRegression.Prediction.train>0.7,1,0)),as.factor(t.l.df$TargetBuy))

logitRegression.Prediction.validate<-predict(logit.reg,v.l.df,type = "response")
confusionMatrix(as.factor(ifelse(logitRegression.Prediction.validate>0.7,1,0)),as.factor(v.l.df$TargetBuy))
#   
#   (m) Plot ROC curves for the decision tree in (f) and the logit model using 
#validation data. Summarize each curve by its ROC index ("area under the curve (AUC)").
#Copy the code used and the result below. In terms of ROC index, which model is better?

install.packages("pROC")
library(pROC)
#decision tree plot on validation data

#it gives u probability based on different thresholds

#when u predict

ValidPRedict.dt<-predict(basic.dt,v.df,type = 'prob')


r<-roc(v.df$TargetBuy,ValidPRedict.dt[,2])#we need second column only because we need probabilty of saying yes
plot.roc(r)
auc(r)

#logit model ROC
l<-roc(v.l.df$TargetBuy,logitRegression.Prediction.validate)#it gives u probability based on different thresholds
plot.roc(l)
auc(l)

#########################################

