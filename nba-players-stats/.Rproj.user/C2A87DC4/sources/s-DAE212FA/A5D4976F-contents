#Author: Jianqing Chen
#Title: Week 6 Class Exercise
#Purpose: Data Preprocessing and Classifcation



## Acceptance of Personal Loan: Universal Bank

#import the data file "UniversalBank_Problems.csv"

bank.df <- read.csv("UniversalBank_Problems.csv")


#explore the data (e.g., income)
hist(bank.df$Income)

#everything looks fine? look into more details. What's wrong? What might be the reason?
hist(bank.df$Income, breaks= 100)#we see so many zero values that means we need to fix that as they can be missing values and not necessary zero.
#we do replacement to zero or NA
#replacement

bank.df[,"Income"]==0 #it checks and return true and false based on equal to zero or not.
#now if zero then true menas we replace with NA
bank.df[,"Income"][bank.df[,"Income"]==0]<-NA

# Drop ID and zip code columns because they are useless column 1 and 5
bank.df<-bank.df[,-c(1,5)]



# partition with random sample

train.index<-sample(c(1:5000),3000)#pick 3000 out of 5000 to train
train.df<-bank.df[train.index,]
valid.df<-bank.df[-train.index,]#validation data

# use rpart() to run a classification tree
# use prp() in rpart.plot to plot tree 

library(rpart)
library(rpart.plot)


# classification tree
# use rpart() to run a classification tree.

# "~" often used to denote a statistical model, 
#where the thing on the left of the ~ is the response 
#and the things on the right of the ~ are the explanatory variables.


default.ct<-rpart(Personal.Loan~.,data=train.df,method = "class")

# plot tree
# use prp() to plot the tree. You can control plotting parameters such as color, shape, 
# and information displayed (which and where).

prp(default.ct)
prp(default.ct,type=1)
# customized tree

# define rpart.control() in rpart() to determine the depth of the tree.
cust.ct<-rpart(Personal.Loan~.,data = train.df,method = "class",maxdepth=2)
prp(cust.ct,type = 1,extra = 1)

#maximum tree
#maximum is 100% perfect only for this data set.
deeper.ct<-rpart(Personal.Loan~.,data = train.df,method = "class",cp=0,minsplit=1)
# plot tree
prp(deeper.ct,type = 1,extra=1) 


# classify records in the validation data.
# set argument type = "class" in predict() to generate predicted class membership.
default.ct.pred.train<-predict(default.ct,train.df,type = "class")
#we are now predicting using the training dataset and known model

# generate confusion matrix for training data
# install "caret" package for confusionMatrix()
install.packages("caret")
library(caret)

install.packages("e1071")
# use class() to check data type of Personal.Loan
class(bank.df$Personal.Loan)# to check the data type

confusionMatrix(default.ct.pred.train,as.factor(train.df$Personal.Loan))
#as.factor used to change to logical data type/category

### repeat the code for the validation set, and the deeper tree

#check screenshot for this week.
deeper.ct.pred.train<-predict(deeper.ct,train.df,type = "class")

#accuracy for this confusion matrix should be 100% for training data set.
confusionMatrix(deeper.ct.pred.train,as.factor(train.df$Personal.Loan))

#now for validation data set this should not be accuracy=1

deeper.ct.pred.valid<-predict(deeper.ct,valid.df,type = "class")
confusionMatrix(deeper.ct.pred.valid,as.factor(valid.df$Personal.Loan))

#accuracy is 0.968 here
#now for custom data set
#small tree to training data set
#accuracy is 0.964
cust.ct.pred.train<-predict(cust.ct,train.df,type = "class")
confusionMatrix(cust.ct.pred.train,as.factor(train.df$Personal.Loan))

#now validation data set small tree
cust.ct.pred.valid<-predict(cust.ct,valid.df,type = "class")
confusionMatrix(cust.ct.pred.valid,as.factor(valid.df$Personal.Loan))
#accuracy is 0.9635 so less than train data set

## logit model
# handle missing value: why? how?
# explore the data (e.g., use na.fail and summary())

summary(bank.df)
# impute

is.na(bank.df$Income)#check true false

mean(bank.df$Income, na.rm = TRUE)#find mean removing NA values

bank.df$Income[is.na(bank.df$Income)]<-mean(bank.df$Income,na.rm=TRUE)#this relace it with a mean.

#now for education missing values those are categorical how to impute
table(bank.df$Education)#to check the frequency
#replace NA with highest frequncy value
bank.df$Education[is.na(bank.df$Education)]<-1 #1 is the highest frequnt value in education

summary(bank.df)
# partition with random sample
#run train and valid data set are updated
train.df<-bank.df[train.index,]
valid.df<-bank.df[-train.index,]#validation data

# run logistic regression
# use glm() (general linear model) with family = "binomial" to fit a logistic 
# regression.

logit.reg<-glm(Personal.Loan~.,data = train.df,family = "binomial")

summary(logit.reg)
# treat Education as categorical (R will create dummy variables)
bank.df$Education <- factor(bank.df$Education, levels = c(1,2,3), labels= c("undergraduate","graduate","Professional"))

# run logit again
train.df<-bank.df[train.index,]
valid.df<-bank.df[-train.index,]#validation data


logit.reg<-glm(Personal.Loan~.,data = train.df,family = "binomial")

summary(logit.reg)

#by abouve u can see in summary instead of one education it is now education graduate,education professional etc


# generate confusion matrix for training data
# use predict() with type = "response" to compute predicted probabilities
logit.reg.pred.train<-predict(logit.reg,train.df,type = "response")
#introduce if else and use to set if accuracy is something then yes else no in confusion matrix which gives us probability
# ifelse(logit.reg.pred.train>0.5,1,0)--returns values 1 if true else 0
confusionMatrix(as.factor(ifelse(logit.reg.pred.train>0.7,1,0)),as.factor(train.df$Personal.Loan))
#depedns on 0.7 or 0.8 0r 0.5 --accuracy changes with them-check

### repeat the code for the validation set
#even lower accuracy
logit.reg.pred.valid<-predict(logit.reg,valid.df,type = "response")
confusionMatrix(as.factor(ifelse(logit.reg.pred.valid>0.7,1,0)),as.factor(valid.df$Personal.Loan))


#ROc curve and AUC

install.packages("pROC")
library(pROC)

r<-roc(train.df$Personal.Loan,logit.reg.pred.train)#it gives u probability based on different thresholds
plot.roc(r)

#when u predict
default.ct<-rpart(Personal.Loan~.,data = train.df,method = "class")
default.ct.pred.train<-predict(default.ct,train.df,type = "prob")


r<-roc(train.df$Personal.Loan,default.ct.pred.train[,2])#we need second column only because we need probabilty of saying yes
plot.roc(r)